{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!pip install h5py\n",
    "!pip install keras==2.1.2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import gc\n",
    "from scipy.io import wavfile\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "#import tensorflow as tf\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#audio length\n",
    "L = 16000\n",
    "\n",
    "#labels to predict\n",
    "legal_labels = 'yes no up down left right on off stop go'.split()\n",
    "\n",
    "#only training data\n",
    "train_data_path = '../data/train/'\n",
    "valid_data_path = '../data/valid/'\n",
    "test_data_path = '../data/test/'\n",
    "\n",
    "print train_data_path\n",
    "print valid_data_path\n",
    "print test_data_path\n",
    "print legal_labels\n",
    "print len(legal_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#helpful functions for audio data\n",
    "def custom_fft(y, fs):\n",
    "    T = 1.0 / fs\n",
    "    N = y.shape[0]\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    # FFT is simmetrical, so we take just the first half\n",
    "    # FFT is also complex, to we take just the real part (abs)\n",
    "    vals = 2.0/N * np.abs(yf[0:N//2])\n",
    "    return xf, vals\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "#make audio less than 1 s to become 1 second\n",
    "def pad_audio(samples):\n",
    "    if len(samples) >= L: return samples\n",
    "    else: return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0))\n",
    "\n",
    "#random sample 1 sec from audio that are more than 1 second\n",
    "def chop_audio(samples, L=16000, num=20):\n",
    "    for i in range(num):\n",
    "        beg = np.random.randint(0, len(samples) - L)\n",
    "        yield samples[beg: beg + L]\n",
    "\n",
    "#transform label\n",
    "def label_transform(labels):\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == '_background_noise_':\n",
    "            nlabels.append('silence')\n",
    "        elif label not in legal_labels:\n",
    "            nlabels.append('unknown')\n",
    "        else:\n",
    "            nlabels.append(label)\n",
    "    return pd.get_dummies(pd.Series(nlabels))\n",
    "  \n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    audio_files = np.array(data['filenames'])\n",
    "#    audio_targets = np.array(data['target_names'])\n",
    "    return audio_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To transform the \"training\" data from audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "new_sample_rate = 16000\n",
    "data = load_files(train_data_path) \n",
    "fnames = data['filenames']\n",
    "y_train = []\n",
    "x_train = []\n",
    "\n",
    "for fname in fnames:\n",
    "    \n",
    "    if fname.endswith('wav'):\n",
    "        \n",
    "        #if audio data is less than 1 second, complete it\n",
    "        sample_rate, samples = wavfile.read(fname)\n",
    "        samples = pad_audio(samples)\n",
    "        \n",
    "        #if audio data is larger than 1 second, chop it\n",
    "        if len(samples) > 16000:\n",
    "            n_samples = chop_audio(samples)\n",
    "        \n",
    "        else: \n",
    "            n_samples = [samples]\n",
    "        \n",
    "        #for silence audio, since it is longer than 1 second\n",
    "        for sample in n_samples:\n",
    "    #        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "            _, _, specgram = log_specgram(sample, sample_rate = new_sample_rate)\n",
    "            x_train.append(specgram)\n",
    "            y_train.append(fname.split(\"/\")[3])\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print time.time() - start\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_train = x_train.reshape(tuple(list(x_train.shape) + [1]))\n",
    "y_train = label_transform(y_train)\n",
    "label_index = y_train.columns.values\n",
    "y_train = y_train.values\n",
    "y_train = np.array(y_train)\n",
    "#del labels, fnames\n",
    "gc.collect()\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To transform the \"validation\" data from audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "data = load_files(valid_data_path)\n",
    "fnames = data['filenames']\n",
    "new_sample_rate = 16000\n",
    "y_valid = []\n",
    "x_valid = []\n",
    "\n",
    "for fname in fnames:\n",
    "    \n",
    "    if fname.endswith('wav'):\n",
    "        \n",
    "        sample_rate, samples = wavfile.read(fname)\n",
    "        samples = pad_audio(samples)\n",
    "        \n",
    "        if len(samples) > 16000:\n",
    "            n_samples = chop_audio(samples)\n",
    "            \n",
    "        else: \n",
    "            n_samples = [samples]\n",
    "        \n",
    "        #for silence audio, since it is longer than 1 second\n",
    "        for sample in n_samples:\n",
    "    #        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "            _, _, specgram = log_specgram(sample, sample_rate = new_sample_rate)\n",
    "            x_valid.append(specgram)\n",
    "            y_valid.append(fname.split(\"/\")[3])\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print time.time() - start\n",
    "\n",
    "x_valid = np.array(x_valid)\n",
    "x_valid = x_valid.reshape(tuple(list(x_valid.shape) + [1]))\n",
    "y_valid = label_transform(y_valid)\n",
    "label_index = y_valid.columns.values\n",
    "y_valid = y_valid.values\n",
    "y_valid = np.array(y_valid)\n",
    "#del labels, fnames\n",
    "gc.collect()\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 15939)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], 15939)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_valid = x_valid.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To show the current shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print x_train.shape\n",
    "print y_train.shape\n",
    "print x_valid.shape\n",
    "print y_valid.shape\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "CNN model and its plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hiddenCell": false
   },
   "outputs": [],
   "source": [
    "#seq model\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "pdrop = .25\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(Dense(200, batch_input_shape=(None, 15939), activation='relu'))\n",
    "model.add(Dropout(pdrop))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(pdrop))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dropout(pdrop))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dropout(pdrop))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "define optimizer, loss function and metrics to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rms_lr = optimizers.RMSprop(lr=0.001)\n",
    "\n",
    "model.compile(optimizer=rms_lr,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"ready\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "filepath='../model/benchmark-{epoch:02d}-{val_acc:.3f}.h5'\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=512, validation_data=(x_valid, y_valid), epochs=50, shuffle=True, verbose=1, callbacks = [checkpoint])\n",
    "\n",
    "model.save('../model/benchmark.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print x_train.shape\n",
    "print y_train.shape\n",
    "print x_valid.shape\n",
    "print y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install keras==2.1.2 \n",
    "#!pip install h5py\n",
    "from keras.models import load_model\n",
    "model = load_model('../model/cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "data = load_files(test_data_path)\n",
    "fnames = data['filenames']\n",
    "new_sample_rate = 16000\n",
    "y_test = []\n",
    "x_test = []\n",
    "\n",
    "for fname in fnames:\n",
    "    \n",
    "    if fname.endswith('wav'):\n",
    "        \n",
    "        sample_rate, samples = wavfile.read(fname)\n",
    "        samples = pad_audio(samples)\n",
    "        \n",
    "        if len(samples) > 16000:\n",
    "            n_samples = chop_audio(samples)\n",
    "            \n",
    "        else: \n",
    "            n_samples = [samples]\n",
    "        \n",
    "        #for silence audio, since it is longer than 1 second\n",
    "        for sample in n_samples:\n",
    "    #        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "            _, _, specgram = log_specgram(sample, sample_rate = new_sample_rate)\n",
    "            x_test.append(specgram)\n",
    "            y_test.append(fname.split(\"/\")[3])\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print time.time() - start\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = x_test.reshape(tuple(list(x_test.shape) + [1]))\n",
    "y_test = label_transform(y_test)\n",
    "label_index = y_test.columns.values\n",
    "y_test = y_test.values\n",
    "y_test = np.array(y_test)\n",
    "#del labels, fnames\n",
    "gc.collect()\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(x_test.shape[0], 15939)\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "x_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "output_path=\"../result/sub-01.csv\"\n",
    "\n",
    "index = []\n",
    "results = []\n",
    "for fnames, imgs in test_data_generator(batch=32):\n",
    "    predicts = model.predict(imgs)\n",
    "    predicts = np.argmax(predicts, axis=1)\n",
    "    predicts = [label_index[p] for p in predicts]\n",
    "    index.extend(fnames)\n",
    "    results.extend(predicts)\n",
    "\n",
    "df = pd.DataFrame(columns=['fname', 'label'])\n",
    "df['fname'] = index\n",
    "df['label'] = results\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print time.time() - start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
